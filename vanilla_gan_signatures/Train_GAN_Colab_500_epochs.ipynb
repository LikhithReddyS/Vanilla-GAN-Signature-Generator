{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ–Šï¸ Vanilla GAN Signature Generator - 500 Epochs Training\n",
        "\n",
        "Train the Vanilla GAN using a **free T4 GPU** for **500 epochs**\n",
        "\n",
        "## âš ï¸ Before Starting:\n",
        "1. Go to **Runtime â†’ Change runtime type â†’ T4 GPU**\n",
        "2. Run all cells in order\n",
        "\n",
        "â±ï¸ **Estimated time:** ~1-2 hours on T4 GPU\n",
        "\n",
        "ðŸ“¸ **Sample images displayed every 10 epochs!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 1: Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âŒ No GPU! Go to Runtime > Change runtime type > T4 GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 2: Clone Repository & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/LikhithReddyS/Vanilla-GAN-Signature-Generator.git\n",
        "\n",
        "# Navigate to the correct directory\n",
        "%cd Vanilla-GAN-Signature-Generator/vanilla_gan_signatures\n",
        "\n",
        "# Create data folder and clear old checkpoints\n",
        "import os\n",
        "import shutil\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "\n",
        "# Clear old checkpoints to start fresh\n",
        "if os.path.exists('checkpoints'):\n",
        "    shutil.rmtree('checkpoints')\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "\n",
        "if os.path.exists('samples'):\n",
        "    shutil.rmtree('samples')\n",
        "os.makedirs('samples', exist_ok=True)\n",
        "\n",
        "print(\"\\nâœ… Setup complete! Old checkpoints cleared.\")\n",
        "print(f\"ðŸ“ Current directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 3: Upload Your Signature Dataset\n",
        "\n",
        "**On your local computer:**\n",
        "1. Go to `d:\\python\\GAN SKILL PROJECT-2\\vanilla_gan_signatures\\data\\processed`\n",
        "2. Select all images â†’ Right-click â†’ Send to â†’ Compressed (zipped) folder\n",
        "3. Click \"Choose Files\" below and upload the zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"ðŸ“ Upload your signature dataset ZIP file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract zip file\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nExtracting {filename}...\")\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('data/processed')\n",
        "    os.remove(filename)  # Clean up zip\n",
        "\n",
        "# Count images (including subdirectories)\n",
        "extensions = ('.png', '.jpg', '.jpeg')\n",
        "count = sum(1 for root, dirs, files in os.walk('data/processed') \n",
        "            for f in files if f.lower().endswith(extensions))\n",
        "print(f\"\\nâœ… Total images found: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 4: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pillow matplotlib tqdm -q\n",
        "print(\"âœ… Dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 5: Train the GAN ðŸš€ (500 Epochs)\n",
        "\n",
        "Training for **500 epochs** with LeakyReLU architecture:\n",
        "- ðŸ“¸ **Sample images shown every 10 epochs**\n",
        "- ðŸ’¾ Checkpoints saved every 50 epochs\n",
        "\n",
        "â±ï¸ **Estimated time:** ~1-2 hours on T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m src.train_vanilla_gan_signatures \\\n",
        "    --epochs 500 \\\n",
        "    --batch_size 128 \\\n",
        "    --data_dir \"data/processed\" \\\n",
        "    --num_workers 2 \\\n",
        "    --checkpoint_interval 50 \\\n",
        "    --sample_interval 10 \\\n",
        "    --show_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 6: View All Training Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "sample_dir = 'samples'\n",
        "if os.path.exists(sample_dir):\n",
        "    samples = sorted([f for f in os.listdir(sample_dir) if f.endswith('.png')])\n",
        "    if samples:\n",
        "        n_samples = min(12, len(samples))\n",
        "        cols = 4\n",
        "        rows = (n_samples + cols - 1) // cols\n",
        "        \n",
        "        fig, axes = plt.subplots(rows, cols, figsize=(16, 4*rows))\n",
        "        axes = axes.flatten() if n_samples > 1 else [axes]\n",
        "        \n",
        "        step = max(1, len(samples) // n_samples)\n",
        "        selected_samples = [samples[i] for i in range(0, len(samples), step)][:n_samples]\n",
        "        \n",
        "        for ax, sample in zip(axes, selected_samples):\n",
        "            img = Image.open(os.path.join(sample_dir, sample))\n",
        "            ax.imshow(img, cmap='gray')\n",
        "            ax.set_title(sample.replace('.png', ''))\n",
        "            ax.axis('off')\n",
        "        \n",
        "        for ax in axes[len(selected_samples):]:\n",
        "            ax.axis('off')\n",
        "        \n",
        "        plt.suptitle('Training Progress - All Epochs', fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(f\"\\nðŸ“Š Total samples: {len(samples)}\")\n",
        "else:\n",
        "    print(\"No samples yet - run training first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 7: Download Trained Models ðŸ“¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "if os.path.exists('checkpoints') and os.listdir('checkpoints'):\n",
        "    checkpoint_files = os.listdir('checkpoints')\n",
        "    print(f\"ðŸ“¦ Found {len(checkpoint_files)} checkpoint files\")\n",
        "    \n",
        "    shutil.make_archive('trained_models_500epochs', 'zip', 'checkpoints')\n",
        "    print(\"\\nðŸ“¥ Downloading trained models...\")\n",
        "    files.download('trained_models_500epochs.zip')\n",
        "else:\n",
        "    print(\"No checkpoints found - run training first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 8: Download Generated Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.path.exists('samples') and os.listdir('samples'):\n",
        "    shutil.make_archive('generated_samples_500epochs', 'zip', 'samples')\n",
        "    print(\"ðŸ“¥ Downloading samples...\")\n",
        "    files.download('generated_samples_500epochs.zip')\n",
        "else:\n",
        "    print(\"No samples found - run training first!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ’¡ After Training:\n",
        "\n",
        "Extract `trained_models_500epochs.zip` to:\n",
        "```\n",
        "d:\\python\\GAN SKILL PROJECT-2\\vanilla_gan_signatures\\checkpoints\n",
        "```"
      ]
    }
  ]
}